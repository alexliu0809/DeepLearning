{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Images are represented as 3D arrays of numbers, with integers between [0, 255]\n",
    "#E.g. 300 * 100 * 3\n",
    "#Width = 300, Height = 100, 3 refers to 3 color channels RGB. Each cell e.g. [4][5][2] (at [4][5] on Blue color)\n",
    "#has a value <= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![1](img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## An Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image Classifier](img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Driven Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. Collect a dataset of images and labels\n",
    "#2. Use Machine Learning to train an image classifier\n",
    "#3. Evaluate the classifier on a withheld set of test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3](img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First-Classifier: Nearest Neighbor Classifier (Classifier: An Algo to classify the images)\n",
    "#Basically the algorithm remember all the training images and their labels.\n",
    "#and then predict the label of an input image s by calculating the distance of s to each training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4](img/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How does this calculate distance?\n",
    "#L1 Distance: Manhattan\n",
    "#L2 Euclidean Distance\n",
    "\n",
    "#The choice of dictance is a HyperParameter. (Algo as a Parameter, not the obvious one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5](img/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7](img/7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How the code Looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](img/6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train func:\n",
    "#remember all the data.\n",
    "#X are the image, y are the labels.\n",
    "#N is the number of training data\n",
    "#predict func:\n",
    "#based on input image set given output labels\n",
    "#for i in xrange:\n",
    "#for every test image:\n",
    "    #find nearest train image with L1 dis\n",
    "    #predict use the label of nearst training image. (return the label of nearst training image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What are the problems?\n",
    "#Not scalable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the k nearest images, have them vote on the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8](img/8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question: how do we set the hyperparameter? How to choose k?\n",
    "#The parameters and k are very problem-independent.\n",
    "#We have to try them all out and see what works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to split test data to try out what hyperparameters work best on test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9](img/9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k-NN is never used for images for:\n",
    "    #terrible performance\n",
    "    #distance metrics on level of whole images can be very unintuitive. \n",
    "    #-- i.e. shift or dark the image, the value changes a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image Classification: We are given a Training Set of labeled images, asked to predict labels on Test Set. \n",
    "#Common to report the Accuracy of predictions (fraction of correctly predicted images)\n",
    "#- We introduced the k-Nearest Neighbor Classifier, \n",
    "#which predicts the labels based on nearest images in the training set\n",
    "#- We saw that the choice of distance and the value of k are hyperparameters that are tuned using a validation set, \n",
    "#or through cross-validation if the size of the data is small.\n",
    "#- Once the best set of hyperparameters is chosen, the classifier is evaluated once on the test set, \n",
    "#and reported as the performance of kNN on that data.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parametric approach: an approach that we need to optimize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9](img/10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use a line to classify to tpyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![11](img/11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x is an input with 32*32*3\n",
    "#W is a parameter matrix. It has a sie 10*3072. It can also be consider as a weight matrix.\n",
    "#i.e. for label i 10 labels, each pixel j has a weight k.\n",
    "#+b is a bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here is an example: suppose an image with 4 pixels, and 3 classes(labels)\n",
    "#if the image is 32*32*3. we stretch it out, so the xi has the length of 32*32*3, looks a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![12](img/12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting a linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What we do here is we trained the data, get the W. \n",
    "#Each line of the is has the same length as x (that is 32*32*3)\n",
    "#We then reshape each line of W(32*32*3) it into a image (A reversion of how we stretch the image)\n",
    "#and here's what we got."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![13](img/13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Q: what would be a very hard set of classes for a linear classifier to distinguish?\n",
    "#Like a square.\n",
    "#1 2\n",
    "#2 1\n",
    "#It is hard to use a line to classify this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Lecture 2 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![14](img/14.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Have a score func f(x,W,b) = Wx + b\n",
    "#The score here is the score of image1,2,3 w.r.t each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Have:\n",
    "#A score func\n",
    "#Todo:\n",
    "#Evaluate score func, and optimize the loss\n",
    "#1.Define a loss function that quantifies our unhappiness with the scores across the training data.\n",
    "#2.Come up with a way of efficiently finding the parameters that minimize the loss function. (optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass SVM Loss Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multiclass svm loss:\n",
    "#Li is the loss function on each instance i\n",
    "#yi is the intended label (e.g. 3)\n",
    "#Xi is the input image.\n",
    "#j is the label that is not Yi (e.g. 1,2,4,5...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![15](img/15.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The full Loss func L on the whole training set is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![16](img/16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q. What if we use sum here? what if we use mean of (Li)^2?\n",
    "# First one does not change the result, second does\n",
    "#Q. What is the min/max of the possible loss L?\n",
    "#ans: 0 - inf\n",
    "#Q. Usually at initialization W are all small, so all s~=0, What is the loss?\n",
    "#ans: nearly 2. You can calculate the initial loss is nearly to a certain number.\n",
    "#This is good to check your algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example Code:\n",
    "#x is an image vector.\n",
    "#y is int-label (a single int representing the correct one)\n",
    "#W is para metrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![17](img/17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Func Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![18](img/18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So now we have defined a loss rate. But there is a Bug\n",
    "#Q.Suppose that we found a W such that L = 0. Is this W unique?\n",
    "#No.No, you can time a constant.\n",
    "#So which one is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Solution:\n",
    "#Weight Regularization.\n",
    "#Use lambdaR(W) to measure whethter W is nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![19](img/19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![20](img/20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax Classifier (Multinomial (not linear) Logistic Regression)\n",
    "# Softmax is also an algo on loss func\n",
    "\n",
    "# Score Func (the same as SVM loss, defined in Lecture 2):\n",
    "# For an input instance\n",
    "# First get the original s(in linear one) for each label.\n",
    "\n",
    "#Loss Func:\n",
    "# for each label k. calculate e^(Sk)\n",
    "# Calculate the unnormalized log probablity by doing e^(Sk)/sum\n",
    "#Li = -logP(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![21](img/21.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![22](img/22.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q. What is the min/max possible loss L_i?\n",
    "#ans:0-inf\n",
    "#Q. usually at initialization W are small numbers, so all s ~= 0. What is the loss?\n",
    "#ans: -log(1/n) n is the number of labels. For debugging your algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A Comparison between SVM and SoftMax\n",
    "#How to calculate the scores:\n",
    "\n",
    "#Notice here's a clear seperation between loss func and score func\n",
    "#SVM and Softmax has the same score func (blue one).\n",
    "#But SVM and Softmax have different operations on raw score(the result in the blue one) and to get the loss func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![23](img/23.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Which one is better:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![24](img/24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recap\n",
    "#Li is the loss on each instance\n",
    "#N is the number of training instances\n",
    "\n",
    "#SVM and Softmax are both loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![25](img/25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How to calculate gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![26](img/26.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#An numeriacal way of calculating gradient example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![27](img/27.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problems: Very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![28](img/28.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparsion between Calculus and Numerical way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![29](img/29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How to do Gradient Desent on W (paras)?\n",
    "#Why it is a minus? gradient is the dir of increasing, want to minimize lossfunc, so minus.\n",
    "#Cons:\n",
    "#But this one Has to evaluate the how trainning set in order to get a single progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![30](img/30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A Improvement:\n",
    "#ONLY use a small portion of the training set to compute the grad.\n",
    "#Evaluate a data batch to make a single progress\n",
    "#Step size is learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![31](img/31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The effects of Step Size:\n",
    "#Epoch basically refers to the training times(go over the whole data once as 1 epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![32](img/32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization on Gradient Desent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basically discuss the way to update your weights (Para) based on weights.grad\n",
    "#Refer to TTIC Lectrue Optimization on SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![33](img/33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What is an image feature?\n",
    "#After getting this features,\n",
    "#We captivate them, and put them on your classifier.\n",
    "\n",
    "#We have a series of feature extraction.\n",
    "#Then put a linear classifier on top of it.\n",
    "#The old one.\n",
    "\n",
    "#New one.\n",
    "#We are learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![34](img\\34.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
