{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lecture 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computational Graph of the classification algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![35](img/35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![36](img\\36.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Turing Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![37](img\\37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Rule of Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of Chain Rule on Back propagation:\n",
    "#Firstly we need to calculate l = f(w,x)\n",
    "#f(y) = 1/y with y = 0.73\n",
    "#dl/dy = dl/df * df/dy = 1 * -(1/x^2). The y here is 1.37. So we have dl/dx = -(1/1.37^2)*1 = -0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![38](img\\38.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then we need to calculate dl/dx on condition that\n",
    "#y = x + 1 with x = 0.37\n",
    "#dl/dx = dl/dy * dy/dx = (-0.53) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![39](img\\39.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Then suppose x = exp^k with k = 1.0\n",
    "#We need to find dl/dk\n",
    "#dl/dk = dl/dx * dx/dk = (e^-1) * (-0.53) = -0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![40](img\\40.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cases when there are multiple inputs:\n",
    "#Both inputs get 1*0.2 = 0.2 becasue it is a plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![41](img\\41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Collapse all those gates that made up sigmoid get into a single sigmoid gate.\n",
    "#Need to compute what is the local gradient(doing differential) and global gradient(the incoming one) of the gate\n",
    "#We get the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![42](img\\42.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns in backward flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![43](img\\43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient add at branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Refer to TTIC Back Propagation:\n",
    "#When a var is appeared in multiple places. Add gradients to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![44](img\\44.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forward/backward API in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![45](img\\45.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In a specific gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![46](img\\46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the files here its just collections of layer gates.\n",
    "#its (every library is) just whole bunch of layers\n",
    "#You put these layer together\n",
    "#Every layer is just implementing a small function piece,\n",
    "#the function piece knows how to forward and backward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![47](img\\47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch MulConstant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![48](img\\48.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients for Vectorized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the things are now vecto\n",
    "#The only thing changes now, x,y,z are vectors\n",
    "#The local graidents which used to be scalar, now\n",
    "#they are in general full JMatrix (2-d Matrix).\n",
    "#JMatrix tells you what is the inflence of every single element in X\n",
    "#on single element of Z. Thats what it stores\n",
    "#The expression of grad is the same.\n",
    "#dZ/dx is an entire JMatrix, dL/dz is an Vector.\n",
    "#So in the end got a (JM * Vector = )vector to change the graident\n",
    "#The slides is a little bit out of order. It should be JM*Vector(z/x * l/z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![49](img/49.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You dont need to calculate all the elements in a JMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![50](img/50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![51](img/51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example of 2-layer NN\n",
    "#Before the score is f=Wx.\n",
    "#we make w more complex.\n",
    "#2-layer one.\n",
    "#What is happening here is:\n",
    "#We have a input x. We muliply it with W.\n",
    "#Then *: Use Activation function/Non-linearity. We have several choices(here is max)\n",
    "#Then one more matrix multiple\n",
    "\n",
    "#3072 numbers going in. Now got thourgh a hidden layer (W1) to get 100 numbers (or whatever).\n",
    "#Then through W2 get 10 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![52](img/52.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Consider This example:\n",
    "#The car class tries to emerge all the cars facing all the directions and all the colors.\n",
    "#One single model is hard to go through all the modes.\n",
    "#Now we have extra number for picking the car facing to the left, picking car facing right.\n",
    "#h is only above 0 when it finds thing in the image (greem,red,facing left ...)\n",
    "#We have a templates for all the modes. (specific types)\n",
    "#W2 weighted sum over them. If any element in h is turned on, we can have a higher score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![53](img/53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train the NN\n",
    "#3 dimensional input. (3 dimensional basically means number of columns)\n",
    "#y is label (binary)\n",
    "#syn0 syn1 are weight\n",
    "#for is optimization\n",
    "#l1 is first layer optimization using sigmoid non-linear \n",
    "#l2 is second layer optimization using sigmoid non-linear\n",
    "#l1_delta, l2_delta: backward pass.\n",
    "#finally update syn0, syn1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![54](img/54.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What activation function do is combine the input w1x1, w2x2,w3x3 using function f(w1x1+w2x2+...) to get a output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![55](img/55.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures of NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We dont have any computation or weights on input layer. So the first one is 2-layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![56](img/56.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Feed-forward computation of a Neural Network\n",
    "## Think of Backpropagation using this as a hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f is actuall in the middle of two layers.\n",
    "#like h1 in the middle of input layer and hidden 1\n",
    "\n",
    "#W could be a [4*3] so it means 4 features, 3 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![57](img/57.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![58](img/58.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap Mini-Batch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are using mini-batch SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![59](img/59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![55](img/55.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cons: \n",
    "#1.Saturated Neurons kill the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![60](img/60.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.Sigmoid outputs are not zero- centered\n",
    "#you can tell this by actually looking at the graph y=f(x)\n",
    "#See, the mean of output is not 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![61](img/61.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Why we want 0-centered Outdata?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![62](img/62.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![63](img/63.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.exp() is a bit compute expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![64](img/64.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![65](img/65.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cons of ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![66](img/66.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![67](img/67.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxout “Neuron”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![68](img\\68.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![69](img\\69.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![70](img\\70.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![71](img\\71.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q. What happens when W=0 init is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![72](img\\72.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First Idea, small random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![73](img\\73.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![74](img\\74.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using 1.0\n",
    "#What do got?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![75](img\\75.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What is good one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![76](img\\76.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#But it does not work for certain problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![77](img\\77.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The init that works for this certain problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![78](img\\78.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bactch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying unit gaussian activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![79](img\\79.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Where to apply the layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![80](img\\80.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![81](img\\81.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pseudo Code. Notice that in practice is a little different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![82](img\\82.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Babysitting the Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step1 Preprocess Data (Seen Above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step2 Choose the architecture:\n",
    "#E.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![83](img\\83.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step3 Check The loss Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![84](img\\84.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![85](img\\85.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step4 Check overfit very small portion of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![86](img/86.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step5 Train Now:\n",
    "#Start With low learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![87](img/87.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Go for Big One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![88](img/88.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binary Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![89](img/89.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find best para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step1: Do a random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![90](img\\90.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step2: Adjust based on search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![91](img\\91.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lossfunctions.tumblr.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![92](img\\92.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other ways of babysitting your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor and visualize the accurac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![93](img\\93.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Track the ratio of weight update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![94](img\\94.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![95](img\\95.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
